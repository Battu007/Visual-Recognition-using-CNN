{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN with 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pradeepsingh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a2ef3c898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT+QUw0/kFMNP5BTDT+TU/wOP4iVkOh85ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1814d5eb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :].reshape((28, 28)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN with 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 22s 452us/step - loss: 0.6292 - acc: 0.7854 - val_loss: 0.4130 - val_acc: 0.8573\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 22s 459us/step - loss: 0.3971 - acc: 0.8609 - val_loss: 0.3575 - val_acc: 0.8743\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 23s 487us/step - loss: 0.3529 - acc: 0.8758 - val_loss: 0.3289 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 21s 439us/step - loss: 0.3236 - acc: 0.8869 - val_loss: 0.3096 - val_acc: 0.8916\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 22s 463us/step - loss: 0.3054 - acc: 0.8903 - val_loss: 0.2842 - val_acc: 0.9013\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 22s 457us/step - loss: 0.2847 - acc: 0.8980 - val_loss: 0.2721 - val_acc: 0.9073\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 21s 446us/step - loss: 0.2729 - acc: 0.9014 - val_loss: 0.2610 - val_acc: 0.9092\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 22s 455us/step - loss: 0.2612 - acc: 0.9068 - val_loss: 0.2560 - val_acc: 0.9105\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 21s 441us/step - loss: 0.2491 - acc: 0.9113 - val_loss: 0.2568 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 19s 397us/step - loss: 0.2398 - acc: 0.9130 - val_loss: 0.2519 - val_acc: 0.9099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2f364f60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 19s 401us/step - loss: 0.2297 - acc: 0.9164 - val_loss: 0.2468 - val_acc: 0.9136\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 20s 424us/step - loss: 0.2253 - acc: 0.9172 - val_loss: 0.2369 - val_acc: 0.9170\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.2181 - acc: 0.9207 - val_loss: 0.2329 - val_acc: 0.9178\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.2073 - acc: 0.9244 - val_loss: 0.2336 - val_acc: 0.9181\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 19s 393us/step - loss: 0.1987 - acc: 0.9287 - val_loss: 0.2416 - val_acc: 0.9131\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.1968 - acc: 0.9280 - val_loss: 0.2250 - val_acc: 0.9211\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 19s 393us/step - loss: 0.1877 - acc: 0.9308 - val_loss: 0.2249 - val_acc: 0.9203\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 19s 398us/step - loss: 0.1844 - acc: 0.9331 - val_loss: 0.2241 - val_acc: 0.9228\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 19s 405us/step - loss: 0.1749 - acc: 0.9375 - val_loss: 0.2182 - val_acc: 0.9243\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 20s 420us/step - loss: 0.1720 - acc: 0.9372 - val_loss: 0.2205 - val_acc: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182362c0f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2557422494411469\n",
      "Test accuracy: 0.9101\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 27s 288ms/step - loss: 0.4757 - acc: 0.8228 - val_loss: 0.4029 - val_acc: 0.8525\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 26s 283ms/step - loss: 0.4126 - acc: 0.8460 - val_loss: 0.3727 - val_acc: 0.8640\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 28s 296ms/step - loss: 0.3949 - acc: 0.8517 - val_loss: 0.3635 - val_acc: 0.8669\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 27s 295ms/step - loss: 0.3773 - acc: 0.8585 - val_loss: 0.3544 - val_acc: 0.8699\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 31s 336ms/step - loss: 0.3674 - acc: 0.8648 - val_loss: 0.3449 - val_acc: 0.8753\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 30s 319ms/step - loss: 0.3579 - acc: 0.8684 - val_loss: 0.3393 - val_acc: 0.8786\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 29s 312ms/step - loss: 0.3547 - acc: 0.8685 - val_loss: 0.3307 - val_acc: 0.8828\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 28s 303ms/step - loss: 0.3474 - acc: 0.8713 - val_loss: 0.3160 - val_acc: 0.8865\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 27s 288ms/step - loss: 0.3437 - acc: 0.8719 - val_loss: 0.3276 - val_acc: 0.8807\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 27s 296ms/step - loss: 0.3375 - acc: 0.8761 - val_loss: 0.3276 - val_acc: 0.8774\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 35s 379ms/step - loss: 0.3331 - acc: 0.8758 - val_loss: 0.3121 - val_acc: 0.8869\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 29s 314ms/step - loss: 0.3311 - acc: 0.8776 - val_loss: 0.3064 - val_acc: 0.8865\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 31s 338ms/step - loss: 0.3287 - acc: 0.8784 - val_loss: 0.3113 - val_acc: 0.8855\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 37s 402ms/step - loss: 0.3223 - acc: 0.8794 - val_loss: 0.3038 - val_acc: 0.8899\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 49s 524ms/step - loss: 0.3173 - acc: 0.8818 - val_loss: 0.2973 - val_acc: 0.8915\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 45s 484ms/step - loss: 0.3180 - acc: 0.8833 - val_loss: 0.2970 - val_acc: 0.8930\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 50s 539ms/step - loss: 0.3099 - acc: 0.8842 - val_loss: 0.2983 - val_acc: 0.8919\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.3081 - acc: 0.8855 - val_loss: 0.3080 - val_acc: 0.8885\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 45s 479ms/step - loss: 0.3081 - acc: 0.8853 - val_loss: 0.2956 - val_acc: 0.8924\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 45s 486ms/step - loss: 0.3038 - acc: 0.8874 - val_loss: 0.2920 - val_acc: 0.8945\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 44s 473ms/step - loss: 0.3030 - acc: 0.8870 - val_loss: 0.2932 - val_acc: 0.8936\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 39s 417ms/step - loss: 0.3027 - acc: 0.8889 - val_loss: 0.2939 - val_acc: 0.8915\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 38s 406ms/step - loss: 0.3013 - acc: 0.8873 - val_loss: 0.2879 - val_acc: 0.8934\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 39s 417ms/step - loss: 0.2955 - acc: 0.8917 - val_loss: 0.2825 - val_acc: 0.9009\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 36s 386ms/step - loss: 0.2935 - acc: 0.8911 - val_loss: 0.2876 - val_acc: 0.8972\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 36s 384ms/step - loss: 0.2897 - acc: 0.8936 - val_loss: 0.2810 - val_acc: 0.9003\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 37s 398ms/step - loss: 0.2847 - acc: 0.8951 - val_loss: 0.2848 - val_acc: 0.8965\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 50s 535ms/step - loss: 0.2840 - acc: 0.8938 - val_loss: 0.2799 - val_acc: 0.8985\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 42s 447ms/step - loss: 0.2880 - acc: 0.8922 - val_loss: 0.2711 - val_acc: 0.9038\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 36s 384ms/step - loss: 0.2867 - acc: 0.8930 - val_loss: 0.2801 - val_acc: 0.8998\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 39s 420ms/step - loss: 0.2831 - acc: 0.8946 - val_loss: 0.2731 - val_acc: 0.9026\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 37s 397ms/step - loss: 0.2848 - acc: 0.8936 - val_loss: 0.2802 - val_acc: 0.9017\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 37s 402ms/step - loss: 0.2804 - acc: 0.8952 - val_loss: 0.2694 - val_acc: 0.9034\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 37s 403ms/step - loss: 0.2750 - acc: 0.8979 - val_loss: 0.2761 - val_acc: 0.9014\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 37s 398ms/step - loss: 0.2714 - acc: 0.8987 - val_loss: 0.2770 - val_acc: 0.8996\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 37s 401ms/step - loss: 0.2795 - acc: 0.8966 - val_loss: 0.2713 - val_acc: 0.9010\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 31s 334ms/step - loss: 0.2748 - acc: 0.8976 - val_loss: 0.2728 - val_acc: 0.9029\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 23s 251ms/step - loss: 0.2702 - acc: 0.8988 - val_loss: 0.2635 - val_acc: 0.9028\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 23s 252ms/step - loss: 0.2722 - acc: 0.8981 - val_loss: 0.2652 - val_acc: 0.9053\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 23s 247ms/step - loss: 0.2688 - acc: 0.9003 - val_loss: 0.2712 - val_acc: 0.9034\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 24s 253ms/step - loss: 0.2721 - acc: 0.8998 - val_loss: 0.2660 - val_acc: 0.9033\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 22s 239ms/step - loss: 0.2662 - acc: 0.9000 - val_loss: 0.2576 - val_acc: 0.9047\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 22s 239ms/step - loss: 0.2652 - acc: 0.9003 - val_loss: 0.2656 - val_acc: 0.9042\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 28s 298ms/step - loss: 0.2635 - acc: 0.9027 - val_loss: 0.2621 - val_acc: 0.9060\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 23s 244ms/step - loss: 0.2620 - acc: 0.9033 - val_loss: 0.2719 - val_acc: 0.9061\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 21s 227ms/step - loss: 0.2629 - acc: 0.9024 - val_loss: 0.2626 - val_acc: 0.9064\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 21s 226ms/step - loss: 0.2648 - acc: 0.9019 - val_loss: 0.2644 - val_acc: 0.9041\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 21s 227ms/step - loss: 0.2599 - acc: 0.9034 - val_loss: 0.2627 - val_acc: 0.9074\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 27s 287ms/step - loss: 0.2595 - acc: 0.9044 - val_loss: 0.2544 - val_acc: 0.9093\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 25s 266ms/step - loss: 0.2614 - acc: 0.9019 - val_loss: 0.2571 - val_acc: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2f7a8940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50,\n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.24125416670441627\n",
      "Test accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "score = cnn1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
