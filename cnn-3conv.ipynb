{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## CNN with 3 Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_path = keras.utils.get_file('train-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-images-idx3-ubyte.gz')\n",
    "train_labels_path = keras.utils.get_file('train-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/train-labels-idx1-ubyte.gz')\n",
    "test_images_path = keras.utils.get_file('t10k-images-idx3-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = keras.utils.get_file('t10k-labels-idx1-ubyte.gz', 'https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/data/fashion/t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(images_path, labels_path):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig = load_mnist(train_images_path, train_labels_path)\n",
    "X_test, y_test = load_mnist(test_images_path, test_labels_path)\n",
    "X_train_orig = X_train_orig.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_orig /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(y_train_orig.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_orig, y_train_orig, test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a31f9fe10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT+QUw0/kFMNP5BTDT+TU/wOP4iVkOh85ugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1817dde048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN with 3 Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 107s 2ms/step - loss: 0.9339 - acc: 0.6526 - val_loss: 0.5534 - val_acc: 0.7863\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 105s 2ms/step - loss: 0.5553 - acc: 0.7890 - val_loss: 0.4435 - val_acc: 0.8358\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 103s 2ms/step - loss: 0.4776 - acc: 0.8221 - val_loss: 0.3985 - val_acc: 0.8570\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.4268 - acc: 0.8425 - val_loss: 0.3546 - val_acc: 0.8758\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 85s 2ms/step - loss: 0.3944 - acc: 0.8564 - val_loss: 0.3250 - val_acc: 0.8848\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 88s 2ms/step - loss: 0.3726 - acc: 0.8614 - val_loss: 0.3084 - val_acc: 0.8909\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 96s 2ms/step - loss: 0.3560 - acc: 0.8688 - val_loss: 0.2956 - val_acc: 0.8948\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.3349 - acc: 0.8783 - val_loss: 0.2804 - val_acc: 0.8997\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 85s 2ms/step - loss: 0.3234 - acc: 0.8801 - val_loss: 0.2776 - val_acc: 0.8992\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.3127 - acc: 0.8845 - val_loss: 0.2744 - val_acc: 0.9030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a326466a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 41s 848us/step - loss: 0.3025 - acc: 0.8873 - val_loss: 0.2638 - val_acc: 0.9045\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 41s 848us/step - loss: 0.2929 - acc: 0.8908 - val_loss: 0.2605 - val_acc: 0.9066\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 41s 846us/step - loss: 0.2794 - acc: 0.8956 - val_loss: 0.2546 - val_acc: 0.9078\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 41s 855us/step - loss: 0.2763 - acc: 0.8975 - val_loss: 0.2478 - val_acc: 0.9118\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 41s 855us/step - loss: 0.2725 - acc: 0.8989 - val_loss: 0.2482 - val_acc: 0.9077\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 41s 860us/step - loss: 0.2628 - acc: 0.8998 - val_loss: 0.2414 - val_acc: 0.9127\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 41s 863us/step - loss: 0.2603 - acc: 0.9031 - val_loss: 0.2401 - val_acc: 0.9110\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 42s 868us/step - loss: 0.2561 - acc: 0.9036 - val_loss: 0.2310 - val_acc: 0.9173\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 41s 864us/step - loss: 0.2470 - acc: 0.9082 - val_loss: 0.2477 - val_acc: 0.9082\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 42s 870us/step - loss: 0.2421 - acc: 0.9107 - val_loss: 0.2298 - val_acc: 0.9175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32bcdb70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.25669838305711745\n",
      "Test accuracy: 0.9059\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "93/93 [==============================] - 50s 538ms/step - loss: 0.4376 - acc: 0.8340 - val_loss: 0.3504 - val_acc: 0.8695\n",
      "Epoch 2/50\n",
      "93/93 [==============================] - 46s 490ms/step - loss: 0.3976 - acc: 0.8517 - val_loss: 0.3414 - val_acc: 0.8722\n",
      "Epoch 3/50\n",
      "93/93 [==============================] - 44s 472ms/step - loss: 0.3918 - acc: 0.8518 - val_loss: 0.3265 - val_acc: 0.8761\n",
      "Epoch 4/50\n",
      "93/93 [==============================] - 44s 472ms/step - loss: 0.3657 - acc: 0.8625 - val_loss: 0.3176 - val_acc: 0.8833\n",
      "Epoch 5/50\n",
      "93/93 [==============================] - 44s 472ms/step - loss: 0.3642 - acc: 0.8650 - val_loss: 0.3028 - val_acc: 0.8891\n",
      "Epoch 6/50\n",
      "93/93 [==============================] - 44s 473ms/step - loss: 0.3571 - acc: 0.8664 - val_loss: 0.3104 - val_acc: 0.8821\n",
      "Epoch 7/50\n",
      "93/93 [==============================] - 44s 473ms/step - loss: 0.3528 - acc: 0.8680 - val_loss: 0.3076 - val_acc: 0.8894\n",
      "Epoch 8/50\n",
      "93/93 [==============================] - 44s 473ms/step - loss: 0.3478 - acc: 0.8711 - val_loss: 0.3034 - val_acc: 0.8882\n",
      "Epoch 9/50\n",
      "93/93 [==============================] - 54s 576ms/step - loss: 0.3424 - acc: 0.8713 - val_loss: 0.2968 - val_acc: 0.8902\n",
      "Epoch 10/50\n",
      "93/93 [==============================] - 46s 489ms/step - loss: 0.3330 - acc: 0.8743 - val_loss: 0.2875 - val_acc: 0.8916\n",
      "Epoch 11/50\n",
      "93/93 [==============================] - 50s 537ms/step - loss: 0.3293 - acc: 0.8760 - val_loss: 0.2837 - val_acc: 0.8955\n",
      "Epoch 12/50\n",
      "93/93 [==============================] - 46s 494ms/step - loss: 0.3243 - acc: 0.8771 - val_loss: 0.2829 - val_acc: 0.8942\n",
      "Epoch 13/50\n",
      "93/93 [==============================] - 44s 478ms/step - loss: 0.3273 - acc: 0.8774 - val_loss: 0.2858 - val_acc: 0.8960\n",
      "Epoch 14/50\n",
      "93/93 [==============================] - 45s 480ms/step - loss: 0.3150 - acc: 0.8822 - val_loss: 0.2806 - val_acc: 0.8946\n",
      "Epoch 15/50\n",
      "93/93 [==============================] - 44s 478ms/step - loss: 0.3185 - acc: 0.8788 - val_loss: 0.2749 - val_acc: 0.8968\n",
      "Epoch 16/50\n",
      "93/93 [==============================] - 44s 478ms/step - loss: 0.3182 - acc: 0.8820 - val_loss: 0.2740 - val_acc: 0.8977\n",
      "Epoch 17/50\n",
      "93/93 [==============================] - 45s 482ms/step - loss: 0.3145 - acc: 0.8829 - val_loss: 0.2719 - val_acc: 0.8977\n",
      "Epoch 18/50\n",
      "93/93 [==============================] - 45s 480ms/step - loss: 0.3122 - acc: 0.8830 - val_loss: 0.2786 - val_acc: 0.8962\n",
      "Epoch 19/50\n",
      "93/93 [==============================] - 45s 483ms/step - loss: 0.3057 - acc: 0.8855 - val_loss: 0.2610 - val_acc: 0.9069\n",
      "Epoch 20/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.3092 - acc: 0.8845 - val_loss: 0.2669 - val_acc: 0.9001\n",
      "Epoch 21/50\n",
      "93/93 [==============================] - 45s 482ms/step - loss: 0.3033 - acc: 0.8866 - val_loss: 0.2790 - val_acc: 0.8941\n",
      "Epoch 22/50\n",
      "93/93 [==============================] - 46s 489ms/step - loss: 0.3005 - acc: 0.8872 - val_loss: 0.2621 - val_acc: 0.9058\n",
      "Epoch 23/50\n",
      "93/93 [==============================] - 45s 483ms/step - loss: 0.2989 - acc: 0.8894 - val_loss: 0.2578 - val_acc: 0.9045\n",
      "Epoch 24/50\n",
      "93/93 [==============================] - 45s 486ms/step - loss: 0.2968 - acc: 0.8883 - val_loss: 0.2595 - val_acc: 0.9050\n",
      "Epoch 25/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.2954 - acc: 0.8889 - val_loss: 0.2594 - val_acc: 0.9043\n",
      "Epoch 26/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.2959 - acc: 0.8896 - val_loss: 0.2597 - val_acc: 0.9041\n",
      "Epoch 27/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.2950 - acc: 0.8892 - val_loss: 0.2580 - val_acc: 0.9046\n",
      "Epoch 28/50\n",
      "93/93 [==============================] - 46s 491ms/step - loss: 0.2910 - acc: 0.8922 - val_loss: 0.2634 - val_acc: 0.9036\n",
      "Epoch 29/50\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.2906 - acc: 0.8906 - val_loss: 0.2541 - val_acc: 0.9053\n",
      "Epoch 30/50\n",
      "93/93 [==============================] - 45s 486ms/step - loss: 0.2922 - acc: 0.8900 - val_loss: 0.2664 - val_acc: 0.9013\n",
      "Epoch 31/50\n",
      "93/93 [==============================] - 45s 487ms/step - loss: 0.2893 - acc: 0.8920 - val_loss: 0.2560 - val_acc: 0.9057\n",
      "Epoch 32/50\n",
      "93/93 [==============================] - 45s 486ms/step - loss: 0.2836 - acc: 0.8943 - val_loss: 0.2590 - val_acc: 0.9005\n",
      "Epoch 33/50\n",
      "93/93 [==============================] - 55s 593ms/step - loss: 0.2841 - acc: 0.8933 - val_loss: 0.2505 - val_acc: 0.9063\n",
      "Epoch 34/50\n",
      "93/93 [==============================] - 62s 668ms/step - loss: 0.2829 - acc: 0.8937 - val_loss: 0.2528 - val_acc: 0.9065\n",
      "Epoch 35/50\n",
      "93/93 [==============================] - 59s 630ms/step - loss: 0.2813 - acc: 0.8950 - val_loss: 0.2504 - val_acc: 0.9068\n",
      "Epoch 36/50\n",
      "93/93 [==============================] - 43s 464ms/step - loss: 0.2776 - acc: 0.8965 - val_loss: 0.2631 - val_acc: 0.9017\n",
      "Epoch 37/50\n",
      "93/93 [==============================] - 44s 474ms/step - loss: 0.2783 - acc: 0.8958 - val_loss: 0.2567 - val_acc: 0.9040\n",
      "Epoch 38/50\n",
      "93/93 [==============================] - 43s 463ms/step - loss: 0.2805 - acc: 0.8946 - val_loss: 0.2459 - val_acc: 0.9101\n",
      "Epoch 39/50\n",
      "93/93 [==============================] - 47s 502ms/step - loss: 0.2804 - acc: 0.8958 - val_loss: 0.2456 - val_acc: 0.9077\n",
      "Epoch 40/50\n",
      "93/93 [==============================] - 46s 493ms/step - loss: 0.2718 - acc: 0.8983 - val_loss: 0.2480 - val_acc: 0.9078\n",
      "Epoch 41/50\n",
      "93/93 [==============================] - 45s 482ms/step - loss: 0.2739 - acc: 0.8970 - val_loss: 0.2454 - val_acc: 0.9085\n",
      "Epoch 42/50\n",
      "93/93 [==============================] - 45s 482ms/step - loss: 0.2742 - acc: 0.8976 - val_loss: 0.2414 - val_acc: 0.9113\n",
      "Epoch 43/50\n",
      "93/93 [==============================] - 61s 657ms/step - loss: 0.2740 - acc: 0.8969 - val_loss: 0.2409 - val_acc: 0.9085\n",
      "Epoch 44/50\n",
      "93/93 [==============================] - 83s 889ms/step - loss: 0.2717 - acc: 0.8980 - val_loss: 0.2519 - val_acc: 0.9076\n",
      "Epoch 45/50\n",
      "93/93 [==============================] - 81s 868ms/step - loss: 0.2713 - acc: 0.8982 - val_loss: 0.2511 - val_acc: 0.9072\n",
      "Epoch 46/50\n",
      "93/93 [==============================] - 82s 884ms/step - loss: 0.2633 - acc: 0.9009 - val_loss: 0.2389 - val_acc: 0.9090\n",
      "Epoch 47/50\n",
      "93/93 [==============================] - 82s 884ms/step - loss: 0.2647 - acc: 0.9000 - val_loss: 0.2452 - val_acc: 0.9076\n",
      "Epoch 48/50\n",
      "93/93 [==============================] - 81s 871ms/step - loss: 0.2746 - acc: 0.8968 - val_loss: 0.2460 - val_acc: 0.9124\n",
      "Epoch 49/50\n",
      "93/93 [==============================] - 81s 868ms/step - loss: 0.2701 - acc: 0.8997 - val_loss: 0.2398 - val_acc: 0.9104\n",
      "Epoch 50/50\n",
      "93/93 [==============================] - 80s 864ms/step - loss: 0.2583 - acc: 0.9025 - val_loss: 0.2441 - val_acc: 0.9108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a32bcd6d8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit_generator(batches, steps_per_epoch=48000//batch_size, epochs=50,\n",
    "                    validation_data=val_batches, validation_steps=12000//batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.246803956669569\n",
      "Test accuracy: 0.9083\n"
     ]
    }
   ],
   "source": [
    "score = cnn2.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
